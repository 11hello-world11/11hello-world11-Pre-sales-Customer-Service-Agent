import os
import asyncio
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_core.messages import HumanMessage, ToolMessage, SystemMessage
from langchain_core.tools import tool

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

@tool
def search_local_knowledge(query: str) -> str:
    """
    Search for answers in local text files within the 'QA_txt' directory.
    Useful for answering general questions about product features, common issues, and opening requirements.
    The tool searches for keywords in 'å¼€åœºäº†è§£éœ€æ±‚è¯æœ¯_QA.txt', 'äº§å“åŠŸèƒ½ä»‹ç»è¯æœ¯_QA.txt', and 'å¸¸è§é—®é¢˜è¯æœ¯_QA.txt'.
    
    Args:
        query: The search query string.
    """
    base_dir = os.path.dirname(os.path.abspath(__file__))
    qa_dir = os.path.join(base_dir, "QA_txt")
    
    if not os.path.exists(qa_dir):
        return f"Error: Directory {qa_dir} does not exist."
    
    results = []
    files_to_search = [
        "å¼€åœºäº†è§£éœ€æ±‚è¯æœ¯_QA.txt", 
        "äº§å“åŠŸèƒ½ä»‹ç»è¯æœ¯_QA.txt", 
        "å¸¸è§é—®é¢˜è¯æœ¯_QA.txt"
    ]
    
    for filename in files_to_search:
        filepath = os.path.join(qa_dir, filename)
        if os.path.exists(filepath):
            try:
                with open(filepath, "r", encoding="utf-8") as f:
                    content = f.read()
                    
                    # ç®€å•çš„å…¨æ–‡æœç´¢
                    if query in content:
                        lines = content.split('\n')
                        for i, line in enumerate(lines):
                            if query in line:
                                context_start = max(0, i - 2)
                                context_end = min(len(lines), i + 5)
                                snippet = "\n".join(lines[context_start:context_end])
                                results.append(f"--- Found in {filename} ---\n{snippet}\n")
                    else:
                        # å°è¯•æ›´å®½æ¾çš„æœç´¢ï¼šå¦‚æœ query æ˜¯é—®å¥ï¼Œå°è¯•æå–å…³é”®è¯
                        # è¿™é‡Œç®€å•å¤„ç†ï¼Œå¦‚æœå®Œå…¨æ²¡æ‰¾åˆ°ï¼Œå°±ä¸è¿”å›
                        pass
                        
            except Exception as e:
                results.append(f"Error reading {filename}: {str(e)}")
    
    if not results:
        return "No direct matches found in local knowledge base."
        
    return "\n".join(results)

@tool
def ask_supervisor_approval(application_details: str) -> str:
    """
    Simulate sending a price application to a supervisor (the human user) and waiting for approval.
    Use this tool when the customer requests a price lower than the calculated price.
    
    Args:
        application_details: A formatted string containing the application details (Size, Config, Price, etc.).
    """
    print("\n" + "="*50)
    print("ğŸ“¢ ã€å‘ä¸»ç®¡ç”³è¯·ä»·æ ¼ã€‘")
    print(application_details)
    print("="*50 + "\n")
    
    # çœŸå®åœ°ç­‰å¾…ç”¨æˆ·ï¼ˆä¸»ç®¡ï¼‰è¾“å…¥
    approval = input("ä¸»ç®¡è¯·æ‰¹å¤ (åŒæ„/æ‹’ç»/å…¶ä»–æŒ‡ä»¤): ")
    return f"ä¸»ç®¡æ‰¹å¤: {approval}"

async def main():
    # 1. å®šä¹‰å¤§æ¨¡å‹ (LLM)
    print("åˆå§‹åŒ– LLM...")
    llm = ChatOpenAI(
        model="deepseek-chat", 
        temperature=0,
        base_url="https://api.deepseek.com",
        api_key=os.environ.get("DEEPSEEK_API_KEY")
    )

    # 2. å‡†å¤‡ MCP Server é…ç½®
    # è¯»å– mcp-mysql-server çš„ç¯å¢ƒå˜é‡æ–‡ä»¶
    base_dir = os.path.dirname(os.path.abspath(__file__))
    mysql_server_dir = os.path.join(base_dir, "mcp-mysql-server")
    mysql_env_path = os.path.join(mysql_server_dir, "env")
    
    mysql_env = os.environ.copy() # ç»§æ‰¿å½“å‰ç¯å¢ƒå˜é‡
    if os.path.exists(mysql_env_path):
        print(f"è¯»å– MySQL ç¯å¢ƒå˜é‡: {mysql_env_path}")
        with open(mysql_env_path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith("#"):
                    try:
                        key, value = line.split("=", 1)
                        mysql_env[key.strip()] = value.strip()
                    except ValueError:
                        pass
    
    # æ„å»ºå¯åŠ¨å‘½ä»¤
    script_path = os.path.join(mysql_server_dir, "node_modules", "@fhuang", "mcp-mysql-server", "build", "index.js")
    
    print(f"MCP Server è„šæœ¬è·¯å¾„: {script_path}")
    
    # 3. åˆå§‹åŒ– MCP Client
    client = MultiServerMCPClient({
        "mysql": {
            "command": "node",
            "args": [script_path],
            "transport": "stdio",
            "env": mysql_env
        }
    })
        
    print("è¿æ¥ MCP Server å¹¶è·å–å·¥å…·...")
    try:
        mcp_tools = await client.get_tools()
        # åˆå¹¶ MCP å·¥å…·å’Œæœ¬åœ°å·¥å…·
        tools = mcp_tools + [search_local_knowledge, ask_supervisor_approval]
        
        print(f"æˆåŠŸè·å– {len(tools)} ä¸ªå·¥å…·: {[t.name for t in tools]}")

        # 4. æ‰‹åŠ¨å®ç°ç®€å•çš„ Agent Loop
        print("å¼€å§‹è¿è¡Œæ™ºèƒ½ä½“... (è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º)")
        
        # è¯»å– System Prompt
        system_prompt_path = os.path.join(base_dir, "system_prompt.txt")
        if os.path.exists(system_prompt_path):
            with open(system_prompt_path, "r", encoding="utf-8") as f:
                system_prompt_content = f.read()
        else:
            system_prompt_content = "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ•°æ®åº“åŠ©æ‰‹ã€‚" # é»˜è®¤ Prompt

        system_prompt = SystemMessage(content=system_prompt_content)
        chat_history = [system_prompt]
        llm_with_tools = llm.bind_tools(tools)

        while True:
            try:
                user_input = input("\nUser: ")
                if user_input.lower() in ["exit", "quit"]:
                    break
            except EOFError:
                break

            # æ„é€ å½“å‰å¯¹è¯çš„æ¶ˆæ¯åˆ—è¡¨
            # å°†ç”¨æˆ·è¾“å…¥åŠ å…¥å†å²
            chat_history.append(HumanMessage(content=user_input))
            
            # è¿™é‡Œçš„ messages æ˜¯å½“å‰æ‰€æœ‰ä¸Šä¸‹æ–‡
            messages = list(chat_history)
            
            # å†…éƒ¨å¾ªç¯ï¼šå¤„ç†å¤šè½®å·¥å…·è°ƒç”¨
            while True:
                # print("Agent æ€è€ƒä¸­...") # å‡å°‘å•°å—¦çš„è¾“å‡º
                try:
                    response = await llm_with_tools.ainvoke(messages)
                    
                    # å°† AI çš„å›ç­”åŠ å…¥å†å²ï¼ˆåŒ…æ‹¬ tool_callsï¼‰
                    # æ³¨æ„ï¼šå¦‚æœæ˜¯ä¸­é—´æ­¥éª¤ï¼Œè¿™ä¸ª response åŒ…å« tool_callsï¼›å¦‚æœæ˜¯æœ€ç»ˆæ­¥éª¤ï¼Œå®ƒåŒ…å«æœ€ç»ˆæ–‡æœ¬
                    messages.append(response)
                    
                    if response.tool_calls:
                        # æ‰“å°æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰
                        if response.content:
                            print(f"\n> æ€è€ƒè¿‡ç¨‹:\n{response.content}\n")

                        # æ‰§è¡Œå·¥å…·
                        for tool_call in response.tool_calls:
                            tool_name = tool_call["name"]
                            tool_args = tool_call["args"]
                            tool_id = tool_call["id"]
                            
                            # æ¨¡æ‹Ÿ UI å¡ç‰‡å±•ç¤º
                            print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")
                            print(f"   å‚æ•°: {tool_args}")
                            
                            # æ‰¾åˆ°å¯¹åº”çš„å·¥å…·å‡½æ•°
                            selected_tool = next((t for t in tools if t.name == tool_name), None)
                            if selected_tool:
                                try:
                                    # å·¥å…·å¯èƒ½æ˜¯åŒæ­¥æˆ–å¼‚æ­¥çš„
                                    tool_result = await selected_tool.ainvoke(tool_args)
                                except Exception as e:
                                    tool_result = f"Error: {e}"
                                
                                # æˆªæ–­è¿‡é•¿çš„è¾“å‡ºï¼Œä¿æŒç•Œé¢æ•´æ´
                                result_str = str(tool_result)
                                display_result = result_str[:200] + "..." if len(result_str) > 200 else result_str
                                print(f"   ç»“æœ: {display_result}\n")
                                
                                # æ·»åŠ å·¥å…·ç»“æœæ¶ˆæ¯åˆ° messages (ç”¨äºä¸‹ä¸€è½®æ€è€ƒ)
                                tool_msg = ToolMessage(content=result_str, tool_call_id=tool_id)
                                messages.append(tool_msg)
                        
                        # ç»§ç»­å†…éƒ¨å¾ªç¯ï¼Œè®© LLM å†æ¬¡æ€è€ƒ
                        continue
                    
                    else:
                        # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¯´æ˜æ˜¯æœ€ç»ˆå›ç­”
                        print("-" * 50)
                        print(f"Final Answer:\n{response.content}")
                        print("-" * 50)
                        
                        # å°†æœ€ç»ˆå›ç­”åŠ å…¥å†å²
                        chat_history.append(response)
                        # å°†ä¸­é—´äº§ç”Ÿçš„å·¥å…·äº¤äº’ä¹Ÿåˆå¹¶åˆ° history ä¸­ï¼Œä¿æŒä¸Šä¸‹æ–‡å®Œæ•´
                        # æ³¨æ„ï¼šæˆ‘ä»¬éœ€è¦æ‰¾å‡º messages ä¸­æ–°å¢çš„éƒ¨åˆ†ï¼ˆé™¤äº†æœ€åä¸€æ¡ responseï¼‰
                        # ç®€å•èµ·è§ï¼Œç›´æ¥æ›´æ–° chat_history ä¸ºå½“å‰çš„ messages
                        chat_history = list(messages)
                        break

                except Exception as e:
                    print(f"å¯¹è¯å¤„ç†å‡ºé”™: {e}")
                    break

    except Exception as e:
        print(f"è¿è¡Œå‡ºé”™: {e}")
    
    # æ³¨æ„: langchain-mcp-adapters ç›®å‰ç‰ˆæœ¬ä¸éœ€è¦æ˜¾å¼å…³é—­ client
    # è¿›ç¨‹ç»“æŸæ—¶ä¼šè‡ªåŠ¨æ¸…ç†å­è¿›ç¨‹

if __name__ == "__main__":
    asyncio.run(main())
